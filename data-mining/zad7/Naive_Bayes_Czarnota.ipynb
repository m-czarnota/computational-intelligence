{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa8fc00e-3dd4-415d-ab26-aedb5005c21b",
   "metadata": {},
   "source": [
    "Zadanie polegało na zaimplementowaniu naiwnego klasyfikatora Bayesa dla danych przygotowanych do przetwarzania przez klasyfikator, aby rozpoznawał on czy przychodząca wiadomość jest typu spam lub nie-spam.\n",
    "Następnie należało dokonać eksperymentów z przygotowanymi zestawami danych: zarówno na pełnych danych, jak dla danych służącymi jako mniejsza część ucząca.\n",
    "Na koniec należało wyciągnąć wnioski z przeprowadzonych eksperymentów."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf2197f-fca7-49ef-8b94-df4f017c5149",
   "metadata": {},
   "source": [
    "Importy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d3ab66a-13db-4fc3-93b4-3838fcb566be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ba9eec-0b0e-48d7-ba47-10a95eded994",
   "metadata": {},
   "source": [
    "Poniżej klasa implementująca naiwny klasyfikator bayesa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "135ec708-bb3b-494a-8f02-1188606d90e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        self.class_labels = None\n",
    "        self.apriori_labels = None\n",
    "        self.condition_probs_distributions = None\n",
    "\n",
    "    def fit(self, x: pd.DataFrame, y: pd.Series):\n",
    "        self.class_labels = y.unique()\n",
    "\n",
    "        self.apriori_labels = self.get_apriori_labels(y)\n",
    "        self.condition_probs_distributions = self.get_condition_probs_distributions(x, y)\n",
    "\n",
    "    def predict(self, x: pd.DataFrame):\n",
    "        return self.class_labels[np.argmax(self.predict_proba(x), axis=1)]\n",
    "\n",
    "    def predict_proba(self, x: pd.DataFrame) -> np.array:\n",
    "        scores = np.ones((x.shape[0], self.class_labels.size))\n",
    "\n",
    "        for document_iter, (document_index, document) in enumerate(x.iterrows()):\n",
    "            for label in self.class_labels:\n",
    "                for word, count in document.items():\n",
    "                    if word not in self.condition_probs_distributions.columns:\n",
    "                        continue\n",
    "\n",
    "                    value = self.condition_probs_distributions.at[label, word]\n",
    "                    scores[document_iter, label] += np.log(value) * count\n",
    "\n",
    "                scores[document_iter, label] += np.log(self.apriori_labels[label])\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def get_apriori_labels(self, y: pd.Series) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Calculates how often class occurs in decisions vector (in our default case 1/2 and 1/2).\n",
    "        \"\"\"\n",
    "        apriori_labels = pd.Series([0] * self.class_labels.size)\n",
    "\n",
    "        for label_iter, label in enumerate(self.class_labels):\n",
    "            apriori_labels[label_iter] = np.sum(y == label) / y.size\n",
    "\n",
    "        return apriori_labels\n",
    "\n",
    "    def get_condition_probs_distributions(self, x: pd.DataFrame, y: pd.Series) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Calculates condition probabilities distributions.\n",
    "        Frequency calc explanation example:\n",
    "            * when label == 1 and word == 543 then +1 in [label, word]\n",
    "        Probs calc explanation example:\n",
    "            * divide each counts in specific label by sum of words count from all documents\n",
    "            * before dividing add +1 to counts as laplace fix\n",
    "        \"\"\"\n",
    "        condition_distributions = pd.DataFrame(0, index=self.class_labels, columns=x.columns)\n",
    "\n",
    "        for document_index, document in x.iterrows():\n",
    "            label = y[document_index]\n",
    "\n",
    "            for word, count in document.items():\n",
    "                condition_distributions.at[label, word] += 1 if count > 0 else 0\n",
    "\n",
    "        for label in self.class_labels:\n",
    "            label_count = self.apriori_labels[label] * x.shape[0]\n",
    "            word_count = x[y == label].applymap(lambda val: 1 if val > 0 else val).sum(axis=0).sum()\n",
    "\n",
    "            condition_distributions.loc[label] = (condition_distributions.loc[label] + 1) / (word_count + x.shape[1])\n",
    "\n",
    "        return condition_distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3104a4-505c-4218-9f2e-19cdf54d9966",
   "metadata": {},
   "source": [
    "Funkcja służąca do wczytania danych oraz przygotowania ich jako macierz, w której wiersze do identyfikatory poszczególnego dokumentu, kolumny to identyfikatory słów występujących w tych dokumentach, a komórka to ilość wystąpień poszczególnego słowa w danym dokumencie.\n",
    "Funkcja zwraca również klasy decyzyjne dla każdego z dokumentów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a7fbcc7-f5e9-4c6d-ba78-1c6434db8953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(size: int = None, data_type: str = 'train'):\n",
    "    data_size = '' if size is None else f'-{size}'\n",
    "\n",
    "    data_train = pd.read_csv(f'./DataPrepared/{data_type}-features{data_size}.txt', names=['document', 'word', 'count'], sep=' ')\n",
    "    data_labels = pd.read_csv(f'./DataPrepared/{data_type}-labels{data_size}.txt', names=['label']).squeeze('columns')\n",
    "    data_labels.index += 1\n",
    "\n",
    "    matrix = pd.DataFrame(data=0, index=data_train['document'].unique(), columns=data_train['word'].unique())\n",
    "\n",
    "    for row_index, row in data_train.iterrows():\n",
    "        document = row['document']\n",
    "        word = row['word']\n",
    "\n",
    "        matrix[word][document] = row['count']\n",
    "\n",
    "    return matrix, data_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed99a31-7f20-4931-9693-b289d1cf42e9",
   "metadata": {},
   "source": [
    "Funkcja pomocnicza wykonująca eksperyment z naiwnym klasyfikatorem bayesa dla zadanego rozmiaru danych dla części trenującej. Zwraca ona dokładność otrzymaną przez testowanie zaimplementowanego klasyfikatora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "694283c5-9749-4b15-a21d-d54810954617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_for_size(size: int = None, train_data: tuple = None, test_data: tuple = None):\n",
    "    matrix_train, data_labels_train = read_data(size) if train_data is None else train_data\n",
    "\n",
    "    naive_bayes = NaiveBayes()\n",
    "    naive_bayes.fit(matrix_train, data_labels_train)\n",
    "\n",
    "    matrix_test, data_labels_test = read_data(data_type='test') if test_data is None else test_data\n",
    "\n",
    "    return naive_bayes.score(matrix_test, data_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa0b7f8-bbba-4a15-b09d-0bbfa06a7869",
   "metadata": {},
   "source": [
    "Funkcje wykonujące eksperymenty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "019fa09a-13d8-4bdb-bfe7-4767d476167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_random():\n",
    "    matrix_train, data_labels_train = read_data()\n",
    "    rng = np.random.default_rng()\n",
    "    random_indexes_to_remove = rng.choice(data_labels_train.size, size=np.random.randint(50), replace=False)\n",
    "\n",
    "    for random_index in random_indexes_to_remove:\n",
    "        matrix_train = matrix_train.drop(random_index)\n",
    "        data_labels_train.drop(random_index)\n",
    "\n",
    "    score = experiment_for_size(train_data=(matrix_train, data_labels_train))\n",
    "    print(f'Removed samples (removed documents) from train part:\\n{random_indexes_to_remove}')\n",
    "    print(f'Accuracy for random train size {data_labels_train.size}: {score}')\n",
    "\n",
    "    \n",
    "def experiment_with_size():\n",
    "    sizes = [50, 100, 400, None]\n",
    "    matrix_test, data_labels_test = read_data(data_type='test')\n",
    "\n",
    "    for size in sizes:\n",
    "        score = experiment_for_size(size, test_data=(matrix_test, data_labels_test))\n",
    "        print(f'Accuracy for train size {size if size is not None else \"all\"}: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541ff1ab-3911-46d5-b4a8-07de6b0c215f",
   "metadata": {},
   "source": [
    "Wykonanie eksperymentu dla różnych rozmiarów części uczącej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2435358-f1cd-4365-87fd-49dc8785fb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for train size 50: 0.9576923076923077\n",
      "Accuracy for train size 100: 0.9730769230769231\n",
      "Accuracy for train size 400: 0.9807692307692307\n",
      "Accuracy for train size all: 0.9807692307692307\n"
     ]
    }
   ],
   "source": [
    "experiment_with_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed19b833-b853-44f9-bb29-26b9087f0eb3",
   "metadata": {},
   "source": [
    "Wnioski do powyższej części:\n",
    "* Im większa część ucząca, tym lepsza klasyfikacja.\n",
    "* Nie jest wymagana bardzo duża liczba dokumentów do satysfakcjonującego nauczenia klasyfikatora, aby otrzymać dużą dokładność.\n",
    "* Przy większej liczbie dokumentów w części uczącej dokładność klasyfikacji jest większa, jednak nie 100%, co oznacza, że wciąż mogą zdarzyć się pojedyncze przypadki, gdzie wiadomość spam zostanie sklasyfikowana jako nie-spam i na odwrót.\n",
    "* Być może dokładności powinny być większe, jednak może to wynikać z błędów implementacji (prawdopodobnie przy wyliczaniu rozkładu warunkowego wystąpień słów w dokumentach pod warunkiem klasy)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b381a621-e8ef-41f0-b448-3691d607beea",
   "metadata": {},
   "source": [
    "Wykonanie eksperymentu dla losowo usuniętych próbek z części uczącej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05050f76-fbdd-41c4-807f-391165119d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed samples (removed documents) from train part:\n",
      "[612 348 465 585   4 119 402 472 342 174 126 424 504 268 519 354 107 478\n",
      " 451 622 110 304 220 621 373 483 450 299 186 496 386 554 698  47 297  23\n",
      " 155  45 356 351 681 103 520 380  56]\n",
      "Accuracy for random train size 700: 0.9807692307692307\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    experiment_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b1c9979-70ba-44e0-9c35-710683745da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed samples (removed documents) from train part:\n",
      "[423 264 515 330 169 211 228 411 297  23  80 405 206 385 146 175  18 531\n",
      " 481 208 681 484 482 430 311 396 101 120 394 347 628 147 651 428]\n",
      "Accuracy for random train size 700: 0.9807692307692307\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    experiment_random()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c985076-6c30-4fbc-a353-ee8de107e832",
   "metadata": {},
   "source": [
    "Wnioski do powyższej części:\n",
    "* Pomimo losowego usuwania próbek z części uczącej, dokładność klasyfikatora wciąż jest wysoka.\n",
    "* Pomimo nierównego rozkładu dokumentów sklasyfikowanych jako spam oraz nie-spam w części uczącej, klasyfikator wciąż radzi sobie bardzo dobrze.\n",
    "* Jednak dokładności te są dokładnie taką samą liczbą i nie różnią się chociaż na dalekim miejscu po przecinku, co jest martwiące.\n",
    "* Problem ten może wynikać z błędów implementacji (prawdopodobnie przy wyliczaniu rozkładu warunkowego wystąpień słów w dokumentach pod warunkiem klasy)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
